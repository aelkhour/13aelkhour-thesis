\chapter{Optimal Motion Planning for Humanoid Robots}
\label{chap:optimal-motion-planning}

The generation of the best possible trajectory that does not violate
any constraints imposed by the environment is an ubiquitous task in
both industrial and humanoid robotics. Numerous examples of successful
robotic applications in the domains of motion planning and optimal
control can be encountered in literature and industry. Very few
however consider the more general problem of optimal motion planning
for complex robots evolving in complex environments.

There are two established but still quite separate research areas that
both address a part of the optimal motion planning problem, namely
path planning and optimal control. This chapter aims at combining
state-of-the-art developments of path planning and optimal control and
to create the algorithmic foundations to tackle optimal control
problems in cluttered environments. We thus propose a two-stage
framework for optimal motion planning on complex robots, where a
quasi-statically feasible path is first planned then optimized in
order to produce a dynamically feasible trajectory. We additionally
describe a simple method to automatically generate minimum bounding
capsules around exact robot body geometries represented by meshes; the
capsules are used to implement distance constraints for an optimal
control problem solver and achieve (self-)collision avoidance. The
whole framework is successfully applied to generate optimal
collision-free trajectories on the humanoid robot HRP-2.

\section{Path Planning}

Sampling-based algorithms, such as Rapidly-exploring Random Trees
(RRT) which were presented in Section
\ref{subsec:chap1-sampling-algorithms}, are particularly powerful when
it comes to solving path planning problems in
high-dimension {\cspace}\thinspace and cluttered environments. In this
chapter, we rely on the same constrained RRT algorithm which was
described in Chapter \ref{subsec:chap2-constraint-motion-planning} in
order to generate statically balanced paths on a submanifold
of {\cspace}.

Let us recall that an important feature of sampling-based algorithms
is their probabilistic completeness, i.e. their capacity to avoid
falling into local minima and to find a solution path if it
exists. They present however three drawbacks. First, due to their
random sampling nature, the configuration \config{} might move in a
random fashion along the path $P$, which could lead to unnecessarily
long paths. Second, we still need to apply a time parametrization in
order to transform the path into a trajectory. This is a non-trivial
task in the particular case of a humanoid robot, as we must ensure its
dynamic balance along the trajectory. Third, the resulting paths are
continuous but not $C^1$; to enforce this constraint, the
time-parameterized motion would need to stop at each waypoint, or
would leave the planned path around waypoints. Additional processing
is thus needed to provide a reshaped collision-free trajectory that
can be executed on the robot.

\section{Numerical Optimization}

We give in Appendix \ref{chap:app-numerical-optimization} an overview
of the most successful numerical optimization techniques that can be
found in the literature. We focus on Jacobian-based methods,
i.e. methods that use information given by the \emph{variations} of
the function we want to minimize to find its minimizer.

\section{Optimal Control}

While the previous section described numerical optimization and its
associated techniques, this section discusses the particular
application of finding, for a dynamic model such as an anthropomorphic
system, a trajectory that allows the model to move over the course of
time from an initial state to a final state, while minimizing a
certain criterion. This particular field is known as \emph{optimal
  control}, and has been a major field of interest in the Robotics
community ever since its creation.

\bigskip

Given a dynamic model, let:
\begin{itemize}[noitemsep,nolistsep]
\item $t$ denotes the time variable,
\item \state{} denotes the state vector,
\item \control{} denotes the control vector,
\item $T$ denotes the trajectory duration,
\item $L$ denotes the Lagrangian term (also cost rate) of the
  objective function,
\item $\Phi$ denotes the Mayer term (also terminal cost) of the
  objective function,
\item \dfcn{} denotes the \emph{Ordinary Differential Equation (ODE)}
  of the model,
\item \eqcstr{} denotes the equality constraint vector function,
\item \ineqcstr{} denotes the inequality constraint vector function,
\item \bndcstr{} denotes the boundary conditions vector function.
\end{itemize}
\vspace{\baselineskip}

An \emph{optimal control problem (OCP)} can be written as follows:

\label{OCP}
\begin{equation}
  \min_{\mathbf{x} (\cdot), \mathbf{u} (\cdot), T} \ \ 
  J(\mathbf{x}(t),\mathbf{u}(T),T) = \int_{0}^{T}L (\mathbf{x}(t), \mathbf{u}(t))dt + \Phi(\mathbf{x}(T))
  \label{OCP:Obj}
\end{equation}
\ \ \ subject to:

\begin{equation}
  \begin{array}{rclr}
  \dot{\mathbf{x}} (t) & = & \mathbf{f}(t, \mathbf{x}(t),
  \mathbf{u}(t)), & t\in[0,T],%
  \label{OCP:Model}%
  \\%
  \mathbf{g}(t, \mathbf{x}(t), \mathbf{u}(t)) & = & \mathbf{0}, & t\in[0,T],%
  \\%
  \mathbf{h}(t, \mathbf{x}(t), \mathbf{u}(t)) & \ge & \mathbf{0}, & t\in[0,T],%
  \\%
  \mathbf{r} (\mathbf{x}(0), \mathbf{x}(T)) & = & \mathbf{0}.%
  \\%
  \end{array}
\end{equation}

Figure \ref{fig:chap3-optimal-control-problem} summarizes the
OCP. Note that it cannot be written (yet) as a finite-dimensional NLP
and use associated solving methods, as $\mathbf{x}(t)$ and
$\mathbf{u}(t)$ are infinite-dimensional.

\begin{figure}
  \centering
      {\def\svgwidth{0.9\linewidth}
        \subimport*{src/chap3-optimal-motion-planning/figure/}
                   {optimal-control-problem.pdf_tex}
      }
      \caption{Illustration of the optimal control problem, showing
        the control and state vectors, path and boundary
        constraints. As the space of continuous functions is
        infinite-dimensional, the general OCP is also
        infinite-dimensional.}
      \label{fig:chap3-optimal-control-problem}
\end{figure}

A significant number of methods which can solve the OCP have been
developed in the past sixty years. They can be classified into three
broad categories: dynamic programming, inverse methods and direct
methods. For more details on dynamic programming and indirect methods,
the interested reader can refer to \cite{laumond1998robot,
  todorov2006optimal}. We give a broad description of the first two
methods and discuss direct methods more deeply, as they are heavily
used in Robotics and Computer Graphics nowadays. Note that the list we
establish is largely inspired by \cite{diehl2006fast}; an even more
exhaustive survey can be found in
\cite{betts1998survey,betts2010practical}.

\subsection{Dynamic Programming}

\emph{Dynamic Programming} is based on Richard Bellman's
\emph{Optimality Principle} \cite{bellman1965dynamic}, which states
that for any OCP going from an initial to a final state, we have a
solution optimal control iff we have a solution optimal control for
the sub-OCP starting from a state reached from the initial state and
going to the final state.

Let $v(\mathbf{x},0) = J(\mathbf{x}(t),\mathbf{u}(t),T)$. Using this
principle, the \emph{Hamilton-Jacobi-Bellman (HJB) Partial
  Differential Equation (PDE)} can be derived for continuous-time
systems:

\begin{equation}
\label{eq:chap3-hjb}
\dot{v}(\mathbf{x},t) + \min_{\mathbf{u} (\cdot)}\left(f(\mathbf{x},
\mathbf{u})^{\top}\nabla_{\mathbf{x}} v(\mathbf{x},t) + L (\mathbf{x},
\mathbf{u},t)\right) = 0,
\end{equation}

subject to the terminal condition:

\begin{equation}
\label{eq:chap3-hjb-cond}
v(\mathbf{x},T)=\Phi(\mathbf{x}(T)).
\end{equation}

$v$ is also called the \emph{value function}. Equation
\equref{eq:chap3-hjb} is the PDE which gives the necessary and
sufficient conditions for finding an optimal control policy. It can be
solved backwards in time, just as in discrete-time dynamic
programming, starting from $t=T$ and ending at $
t=0$. State-of-the-art solvers which rely on finite-element methods
are then used to solve it. However, as the PDE contains partial
derivatives with respect to both time and state, solvers suffer from
the curse of dimensionality and the HJB equation is not used for
large-scale systems in practice.

\subsection{Indirect Methods}

Another fundamental idea in optimal control is the \emph{Maximum (or
  Minimum) Principle}, introduced by Pontryagin
\cite{boltyanskii1960theory}. It also gives sufficient and necessary
conditions for optimal control, and leads to the same solutions as the
optimality principle. It can be derived indirectly from the HJB
equation, by first hiding the value function gradient in a
\emph{costate} vector:

\begin{equation}
  \mathbf{p}(t) = \nabla_{\mathbf{x}} v(\mathbf{x},t),
\end{equation} 

and defining the \emph{Hamiltonian} as the objective function in the
HJB PDE:

\begin{equation}
  \mathcal{H}(\mathbf{x},\mathbf{u},\mathbf{p},t) = f(\mathbf{x},
  \mathbf{u})^{\top}\mathbf{p}(t) + L (\mathbf{x}, \mathbf{u},t)
\end{equation}

These new definitions lead to Pontryagin's minimum principle
sufficient and necessary conditions:

\begin{equation}
\begin{array}{rcl}
\dot{\mathbf{x}}(t) &=&
\frac{\partial}{\partial\mathbf{p}}\mathcal{H}(\mathbf{x},\mathbf{u},\mathbf{p},t)
\\ -\dot{\mathbf{p}}(t) &=&
\frac{\partial}{\partial\mathbf{x}}\mathcal{H}(\mathbf{x},\mathbf{u},\mathbf{p},t)
\\ \mathbf{u}(t) &=&
\text{arg}\min_{\mathbf{u}(\cdot)}\mathcal{H}(\mathbf{x},\mathbf{u},\mathbf{p},t).
\end{array}
\end{equation}

Remarkably, this transformation turns the HJB PDE into a
$2n$-dimensional ODE which can be solved with standard boundary value
problems with linear complexity. Furthermore, deriving the optimal
control policy consists in minimizing the Hamiltonian, which is very
easy in the particular case where controls appear linearly in the
dynamics and quadratically in the cost rate.

\subsection{Direct Methods}
\label{subsec:chap3-direct-methods}

Dynamic programming and indirect methods are used to solve the exact
OCP. Direct methods, on the other hand, rely on first discretizing the
controls and/or the states: this effectively transcribes the
infinite-dimensional OCP into a finite dimensional NLP, which can be
solved using standard numerical optimization techniques. This allows
handling all constraints more easily, and, surprisingly, can lead to
better performance than exact methods, as specialized solvers can take
advantage of the high sparsity of the NLP, i.e. the fact that the
associated gradients contain a large number of zeros. The major
drawback of such methods comes from the fact that we only obtain an
approximate solution of the OCP, but a proper choice of discretization
gives good results in practice. Nowadays direct method are the most
commonly used methods due to their easy applicability to large-scale
problems and their robustness.

\subsubsection{Direct Single-Shooting}

In \emph{direct single-shooting methods}
\cite{hicks1971approximation,sargent1978development}, the control
vector $\mathbf{u}(t)$ is discretized on a fixed grid
$0=t_0<t_1<\ldots<t_N=T$. The state vector $\mathbf{x}(t)$ is regarded
as a dependent variable on $[0,T]$; numerical integration is then used
in order to obtain, starting from an initial state $\mathbf{x}(0)$,
the state as a function $\mathbf{x}(t,\mathbf{q})$ of finitely many
control parameters
$\mathbf{q}=(\mathbf{q}_0,\mathbf{q}_1,\ldots,\mathbf{q}_{N-1})$. Examples
of possible parameterizations include but are not limited to piecewise
constant, piecewise linear, continuous piecewise linear functions.

Once the control discretization is achieved and a numerical ODE
solution is found, we obtain the following finite-dimension NLP:

\begin{equation}
  \min_{\mathbf{q}\in\mathbb R^{nN}} \ \ \int_{0}^{T}L (\mathbf{x}(t,\mathbf{q}),
  \mathbf{u}(t,\mathbf{q}))dt + \Phi(\mathbf{x}(T,\mathbf{q}))
\end{equation}
\ \ \ subject to:
\begin{equation}
  \begin{array}{rclr}
  \mathbf{g}(\mathbf{x}(t_i,\mathbf{q}), \mathbf{u}(t_i,\mathbf{q})) & = & \mathbf{0}, & i=0,\ldots,N,%
  \\%
  \mathbf{h}(\mathbf{x}(t_i,\mathbf{q}), \mathbf{u}(t_i,\mathbf{q})) & \ge & \mathbf{0}, & i=0,\ldots,N,%
  \\%
  \mathbf{r} (\mathbf{x}(0,\mathbf{q}), \mathbf{x}(T,\mathbf{q})) & = & \mathbf{0}.%
  \\%
  \end{array}
\end{equation} 

Figure \ref{fig:chap3-optimal-control-problem-single-shoot} shows an
example of the control discretization and state numerical integration,
using a piecewise constant control parameterization $\mathbf{q}$.

\begin{figure}
  \centering
      {\def\svgwidth{0.9\linewidth}
        \subimport*{src/chap3-optimal-motion-planning/figure/}
                   {optimal-control-problem-single-shoot.pdf_tex}
      }
      \caption{Solving the OCP with direct single-shooting methods:
        the controls are discretized on a coarse grid, and the state
        trajectory is found by numerical integration of the model ODE
        starting from an initial value. In this example, the
        discretized control $\mathbf{u}(t,\mathbf{q})$ is a piecewise
        constant function, and it is equal to $\mathbf{q}_i$ on
        sub-interval $i$.}
      \label{fig:chap3-optimal-control-problem-single-shoot}
\end{figure}

Single-shooting methods present several advantages: they only need an
initial guess of the control parameterization $\mathbf{q}$, and they
can rely on state-of-the-art ODE solvers to obtain the corresponding
state $\mathbf{x}(t,\mathbf{q})$. Due to this fact, the underlying SQP
problem has few degrees of freedom, even for large-scale ODE
systems. However, because the state vector cannot be initialized, we
cannot use the state knowledge to initialize it. This is problematic
in tracking problems for instance, where we want to find an optimal
policy starting from a good initial state trajectory. Furthermore,
some ODE systems can be highly nonlinear and unstable (imagine a
propelled rocket system); it can be very difficult to stabilize such
systems over long trajectories and to make them achieve terminal
constraints just by modifying $\mathbf{x}(0)$ and $\mathbf{q}$.

\subsubsection{Direct Collocation}

\emph{Direct collocation methods}, as described in
\cite{tsang1975optimal}, discretize both control and state vectors on
a \emph{fine} grid with node values
$\mathbf{q}_i\approx\mathbf{u}(t_i)$
$\mathbf{s}_i\approx\mathbf{x}(t_i)$ respectively. This allows
replacing the infinite ODE by finitely many equality constraints, and
approximating the Lagrangian term in the objective function. Using
forward differentiation for instance would give:

\begin{equation}
  \begin{array}{rcl}
    \dot{\mathbf{x}}(t) -
    \mathbf{f}(\mathbf{x}(t)),\mathbf{u}(t)) & = & \mathbf{0}, \qquad t\in[0,T] \\
    & \Downarrow  & \text{\scriptsize forward differentiation}\\
    \mathbf{c}_i(\mathbf{q}_i,\mathbf{s}_i,\mathbf{s}_{i+1}) =
    \frac{\mathbf{s}_{i+1}-\mathbf{s}_i}{t_{i+1}-t_i} -
    \mathbf{f}\left(\frac{\mathbf{s}_{i}+\mathbf{s}_{i+1}}{2},
    \mathbf{q_i}\right) & = & \mathbf{0}, \qquad i=0,1,\ldots,N-1
  \end{array}
\end{equation}

and

\begin{equation}
  \begin{array}{c}
    \int_{0}^{T}L (\mathbf{x}(t), \mathbf{u}(t))dt \\ 
    \Downarrow \\
    \sum_{i=0}^{N-1}l_i(\mathbf{q}_i,\mathbf{s}_i,\mathbf{s}_{i+1})=\sum_{i=0}^{N-1}L\left(\frac{\mathbf{s}_{i}+\mathbf{s}_{i+1}}{2},
    \mathbf{q_i}\right)(t_{i+1}-t_i)
  \end{array}
\end{equation}

Using this discretization, we obtain a large but sparse NLP. It can be
solved using efficient SQP or IPM solvers which are specialized for
sparse problems, such as \textsc{SNOPT} \cite{gill2002snopt} and \textsc{IPOPT}
\cite{Biegler2009}:

\begin{equation}
  \min_{\mathbf{s}\in\mathbb R^{nN},\mathbf{q}\in\mathbb R^{nN}} \ \ \sum_{i=0}^{N-1}l_i(\mathbf{q}_i,\mathbf{s}_i,\mathbf{s}_{i+1}) + \Phi(\mathbf{s}_N)
\end{equation}
\ \ \ subject to:
\begin{equation}
  \begin{array}{rclr}
    \mathbf{c}_i(\mathbf{q}_i,\mathbf{s}_i,\mathbf{s}_{i+1}) & = & \mathbf{0}, & i=0,\ldots,N,%,
    \\
    \mathbf{g}(\mathbf{s}_i,\mathbf{q}_i) & = & \mathbf{0}, & i=0,\ldots,N,%
    \\%
    \mathbf{h}(\mathbf{s}_i,\mathbf{q}_i) & \ge & \mathbf{0}, & i=0,\ldots,N,%
    \\%
    \mathbf{r} (\mathbf{s}_0, \mathbf{s}_N) & = & \mathbf{0}.%
    \\%
  \end{array}
\end{equation} 

\paragraph{State Parameterization}
One particular case occurs when the control and state derivatives can
be directly derived from the states. There is thus no need to
discretize the controls, which are here dependent variables, and only
the states are discretized. The states can then be represented by
smooth functions such as polynomials or splines
\cite{sirinesa1981}. This approach offers the advantage of leading to
a NLP with a smaller number of variables than in the general case of
direct collocation, and is quite common in robotics.

To conclude, direct collocation methods transcribe the OCP into a
large-scale, but very sparse NLP, which can be solved by efficient
solvers. It can treat unstable systems well, offering robust handling
of path and terminal constraints. Furthermore, the state
discretization is such that convenient state trajectories can be used
as an initial guess, which is not the case for single-shooting
methods. However, not all ODE solvers can be used as some of the most
efficient ones use an adaptive-step scheme to perform state
integration; this indeed requires changing the discretization grid
during the optimization process, and leads to a change in the NLP
dimensions.

\subsubsection{Direct Multiple-Shooting}
\label{subsubsec:chap3-direct-multiple-shooting}

\emph{Direct multiple-shooting methods} \cite{Bock1984} were devised
as hybrid methods between single-shooting and collocation methods;
they are based on a coarse discretization of the control vector
$\mathbf{u}(t)=\mathbf{q}_i$ for $t\in\left[t_i,t_{i+1}\right]$, and
the addition of initial state values $\mathbf{s}_i$ for the state
vector. These nodes serve as initial values for the numerical
integration of the ODE over each sub-interval $[t_i,t_{i+1}]$:

\begin{equation}
\begin{array}{rcl}
\dot{\mathbf{x}}_i(t,\mathbf{s}_i,\mathbf{q_i}) &=&
\mathbf{f}(\mathbf{x}_i(t,\mathbf{s}_i,\mathbf{q}_i),\mathbf{q}_i),
\quad t\in\left[t_i,t_{i+1}\right], \\
\mathbf{x}_i(t,\mathbf{s}_i,\mathbf{q}_i) &=& \mathbf{s}_i.
\end{array}
\end{equation} 

\begin{figure}
  \centering
      {\def\svgwidth{0.9\linewidth}
        \subimport*{src/chap3-optimal-motion-planning/figure/}
                   {optimal-control-problem-multiple-shoot.pdf_tex}
      }
      \caption{Solving the OCP with direct multiple-shooting methods:
        controls are discretized on a coarse grid, and several initial
        values for the state are given. The state trajectory is
        computed on each sub-interval by numerical integration of the
        model ODE starting from the node values. Note that the whole
        trajectory is not continuous, and additional continuity
        constraints need to be added.}
      \label{fig:chap3-optimal-control-problem-multiple-shoot}
\end{figure}

Similarly, the Lagrangian term can be numerically integrated over each
sub-interval:

\begin{equation}
l_i(\mathbf{s}_i,\mathbf{q}_i) =
\int_{t_i}^{t_{i+1}}L(\mathbf{x}_i(t_i,\mathbf{s}_i,\mathbf{q}_i),\mathbf{q}_i)dt
\end{equation}

Trajectory pieces $\mathbf{x}_i(t,\mathbf{s}_i,\mathbf{q}_i)$ are then
generated, as shown in Figure
\ref{fig:chap3-optimal-control-problem-multiple-shoot}. We can see
that the whole trajectory is not necessarily continuous; we introduce
continuity conditions to ensure state continuity over the whole
duration, and the obtained finite-dimensional NLP is:

\begin{equation}
  \min_{\mathbf{s}\in\mathbb R^{nN},\mathbf{q}\in\mathbb R^{nN}}
  \ \ \sum_{i=0}^{N-1}l_i(\mathbf{s}_i,\mathbf{q}_i) +
  \Phi(\mathbf{s}_N)
\end{equation}
\ \ \ subject to:
\begin{equation}
  \begin{array}{rcll}
   \mathbf{x}_i(t_{i+1},\mathbf{s}_i,\mathbf{q}_i) - \mathbf{s}_{i+1} &
    = & \mathbf{0}, & \quad i=0,\ldots,N-1,\\%
    \mathbf{g}(\mathbf{s}_i,\mathbf{q}_i) & = & \mathbf{0}, & \quad i=0,\ldots,N,%
    \\%
    \mathbf{h}(\mathbf{s}_i,\mathbf{q}_i) & \ge & \mathbf{0}, & \quad i=0,\ldots,N,%
    \\%
    \mathbf{r} (\mathbf{s}_0,\mathbf{s}_N) & = & \mathbf{0}.%
    \\%
  \end{array}
\end{equation} 

Let us summarize all variables $\mathbf{s}_i$ and $\mathbf{q}_i$ in
one single vector as:

\begin{equation}
\mathbf{w}=(\mathbf{s}_0,\mathbf{q}_0,\mathbf{s}_1,\mathbf{q}_1,\ldots,\mathbf{s}_N)
\in \mathbb R^{2nN},
\end{equation} 

and let us gather continuity (including boundary), equality and
inequality constraints in three vectors $\mathbf{C}$,$\mathbf{G}$ and
$\mathbf{H}$ respectively. We can then rewrite the NLP problem as:

\begin{equation}
  \min_{\mathbf{w}\in\mathbb R^{2nN}}F(\mathbf{w}) \quad\text{such that }
  \left\{
    \begin{array}{rcl}
      \mathbf{C}(\mathbf{w}) &=& \mathbf{0},\\
      \mathbf{G}(\mathbf{w}) &=& \mathbf{0},\\
      \mathbf{H}(\mathbf{w}) &\ge& \mathbf{0}.\\
    \end{array}
    \right.
\end{equation}

This NLP can be solved iteratively using an SQP method, where each
step consists in building the approximate QP subproblem around the
current iterate, as seen in Section \ref{subsubsec:chap3-sqp}. The QP
subproblem is written as:

\begin{equation}
  \min_{\mathbf{p}\in\mathbb R^{2nN}}
  \frac{1}{2}\mathbf{p}^\top\nabla^2_{\mathbf{w}\mathbf{w}}\mathcal{L}\mathbf{p} + \nabla
  F^\top\mathbf{p},
  \quad \text{such that }
  \left\{\begin{array}{rcl}
  \mathbf{C} + \nabla \mathbf{C}^\top\mathbf{p} &=& \mathbf{0},\\
  \mathbf{G} + \nabla \mathbf{G}^\top\mathbf{p} &=& \mathbf{0},\\
  \mathbf{H} + \nabla \mathbf{H}^\top\mathbf{p} &\ge& \mathbf{0},\\
  \end{array}\right.
\end{equation}

where $\mathbf{p}=
(\Delta\mathbf{s}_0,\Delta\mathbf{q}_0,\Delta\mathbf{s}_1,\Delta\mathbf{q}_1,\ldots,\Delta\mathbf{s}_N)$,
and $\mathcal{L}$ is the Lagrangian of $F$.

If we give a closer look at the first equality constraint, we notice
that each block-component can be written as:

\begin{equation}
\label{eq:chap3-ms-recurrence}
\begin{array}{c}
\mathbf{c}_i +
\mathbf{X}_i^\mathbf{s}\Delta\mathbf{s}_i +
\mathbf{X}_i^\mathbf{q}\Delta\mathbf{q}_i - \Delta\mathbf{s}_{i+1}=\mathbf{0}, \quad i=0,\ldots,N-1\\
\Updownarrow\\
\Delta\mathbf{s}_{i+1}=\mathbf{c}_i + \mathbf{X}_i^\mathbf{s}\Delta\mathbf{s}_i +
\mathbf{X}_i^\mathbf{q}\Delta\mathbf{q}_i, \quad i=0,\ldots,N-1,\\
\end{array}
\end{equation}

where $\mathbf{X}_i^\mathbf{s}$ and $\mathbf{X}_i^\mathbf{q}$ are the
Jacobians of $\mathbf{x}(t_{i+1},\mathbf{s}_i,\mathbf{q}_i)$ with
respect to $\mathbf{s}$ and $\mathbf{q}$ respectively.

This leads to two conclusions: first, the continuity constraint vector
Jacobian $\mathbf{C}^\top$ is block-sparse (it can be similarly shown
that it is also the case for the other constraints gradients and the
Lagrangian Hessian). Second, there exists a recurrence relation
between $\Delta\mathbf{s}_{i+1}$ and $\Delta\mathbf{s}_i$ for
$i=0,\ldots,N-1$. This gives way for a \emph{condensing strategy},
where the variables $\Delta\mathbf{s}_i, i=1,\ldots,N$ are eliminated
from the KKT system, and a reduced and simpler system is solved for
the vector:

\begin{equation}
  \mathbf{w}' =
  (\Delta\mathbf{s}_0,\Delta\mathbf{q}_0,\Delta\mathbf{q}_1,
  \ldots,\Delta\mathbf{q}_{N-1})
\end{equation}

The eliminated variables can then be reconstructed, starting from
$\Delta\mathbf{s}_0$, using the recurrence relation from Equation
\equref{eq:chap3-ms-recurrence}.

The condensing strategy allows then to make advantage of the QP
subproblem sparsity, and leads to an efficient SQP strategy. Such a
method can be found in the \textsc{MUSCOD-II}
\cite{leineweber2003efficient1,leineweber2003efficient2} and
\textsc{ACADO} \cite{houska2010acado} multiple-shooting optimal
control solvers.

To conclude, direct multiple-shooting methods offer several
advantages: they rely on a coarse discretization of both control and
state vectors, using adaptive-step ODE solvers to integrate the state
on the sub-intervals. They can thus use knowledge of the state at
initialization, which makes them very suitable for applications where
a good initial guess of the state can be given. Furthermore, the
multiple-shooting scheme allows robust handling of all constraints,
and can be potentially easy to parallelize. While its underlying NLP
is not as sparse as in direct collocation methods, multiple-shooting
methods are particularly powerful thanks to the condensing strategy,
which takes advantage of the QP subproblem sparsity, and is used to
solve them efficiently.

\subsection{Non-Jacobian-Based Optimal Control}
\label{subsec:chap3-non-jacobian}

Note that for all methods we described above, the objective, dynamics
and constraint functions can be nonlinear. They must be, however, at
least $C^1$ so that the solvers can get an idea of the function local
shapes and know where to look for the minimizer while obeying the
constraints. This requirement can be alleviated by the use of non
gradient-based optimal control methods.

We described a random optimization method in Section
\ref{subsubsec:chap3-random-optimization}. It is a shortcut heuristic,
and can be seen as an optimal control method which does not need the
function Jacobians. If shortcut heuristics are applied in the state
space, the resulting trajectory has a lower cost than the original
one. However, no solution can be found outside the bounding box of the
original trajectory due to the fact that the iterative process picks
points to shortcut that are on the trajectory. Shortcut methods get
easily stuck in local minimizers.

Another example is RRT$^*$ \cite{Karaman2011}: it is a variant of the
RRT sampling-based planner that relies on a simultaneous exploration
of the configuration space and rewiring of the exploration tree so
that it contains only low-cost connections. This exploration-rewiring
iterative process continues even after one solution has been found,
and it offers the interesting property of asymptotic convergence
towards the \emph{global} minimum-cost collision-free path. It is also
shown that, in practice, the running time until an acceptable
minimizer is reached is greater than the time needed to find any
collision-free solution by only a constant factor. Of course, if we
want to generate an optimal trajectory, we need to explore not only
the configuration space {\cspace}, but at least the whole state space
{\sspace} (if not the space of both states and controls), where an
element of {\sspace} is \state{}. In this case, the exploration might
become too large to have tractable performance. Another problem arises
from choosing the correct metric for choosing nearest neighbors, as
well as the local optimal steering method. In \cite{Perez2012}, the
authors propose a variant which uses the local linearization of a
system to derive both coherent metric and extension method. Results
have so far been only obtained on simple systems, and this method has
yet to be tested on complex ones. Nevertheless, RRT$^*$ is an
interesting approach as only one algorithm is needed to achieve global
optimal motion planning.

\section{Anthropomorphic System Dynamics}

If we want to be able to generate feasible motions for anthropomorphic
systems, we need to take into account their dynamics in the OCP
formulation. Such underactuated systems are modeled by a rigid body
kinematic tree attached to a floating base, as mentioned in Section
\ref{subsec:chap1-underactuated-systems}; therefore a motion
feasibility cannot be guaranteed unless dynamic balance constraints
are enforced over the whole trajectory duration. We give in this
section a brief overview about a floating-base system dynamics
computation and the dynamic balance conditions. A complete description
of state-of-the-art efficient dynamics algorithms can be found in
\cite{feat08}.

\subsection{Expressing Dynamics with Spatial Algebra}

Usually, rigid body dynamics are written using 3D vector notations
which keeps the translation and rotation parts of dynamic quantities
apart: linear velocities vs angular velocities, forces vs torques,
linear momentum vs angular momentum, etc. We introduce here 6D
\emph{spatial vectors} and their associated \emph{spatial algebra}
\cite{feat08}: they allow to have a compact representation of dynamic
quantities, which leads to increased performance of their associated
operators.

For instance let us assume that we have a rigid body $\mathcal{B}$
with two coordinate systems $A$ and $B$; each of them has an
associated Cartesian frame and coordinates system. Let
$\tensor*[^A]{\mathbf{v}}{}$ and $\tensor*[^A]{\boldsymbol{\omega}}{}$
denote the body linear and angular velocity in $A$ coordinates. We
have then the following relations:

\begin{equation}
\label{eq:chap3-transf-3d-vectors}
\begin{array}{rcl}
  \tensor*[^B]{\mathbf{v}}{} &=&
  \mathbf{E}(\tensor*[^A]{\mathbf{v}}{} -
  \mathbf{r}\times\tensor*[^A]{\boldsymbol{\omega}}{})\\%
  \tensor*[^B]{\boldsymbol{\omega}}{} &=&
  \mathbf{E}\tensor*[^A]{\boldsymbol{\omega}}{}
\end{array}
\end{equation}

where $r=\overset{\longrightarrow}{AB}$ is the translation vector
between the two coordinate systems, and $\mathbf{E} =
\tensor*[^B]{\mathbf{R}}{_A}$ is the rotation matrix from $A$ to $B$.

Let us define the 6D spatial velocity vector:
\begin{equation}
  \tensor*[^A]{\mathbf{v}}{^s}=
  \left(\begin{matrix}
    \tensor*[^A]{\boldsymbol{\omega}}{}\\
    \tensor*[^A]{\mathbf{v}}{}
  \end{matrix}\right)
\end{equation}

We can then rewrite Equation \equref{eq:chap3-transf-3d-vectors} as:

\begin{equation}
  \tensor*[^B]{\mathbf{v}}{^s}=
  \tensor*[^B]{\mathbf{X}}{_A}
  \tensor*[^A]{\mathbf{v}}{^s}
  ,\quad
  \tensor*[^B]{\mathbf{X}}{_A}=
    \left(\begin{matrix}
    \mathbf{E} & \mathbf{0} \\
    -\mathbf{E}\mathbf{r}\times & \mathbf{E}
  \end{matrix}\right)
\end{equation}

The same relation holds for both spatial velocities and accelerations,
which are both referred to by the term \emph{spatial motions}.
Similarly, we can define a coordinate transformation relation for
spatial forces:

\begin{equation}
  \tensor*[^B]{\mathbf{f}}{^s}=
  \tensor*[^B]{\mathbf{X}}{^*_A}
  \tensor*[^A]{\mathbf{f}}{^s}
  ,\quad
  \tensor*[^A]{\mathbf{f}}{^s}=
  \left(\begin{matrix}
    \tensor*[^A]{\mathbf{n}}{}\\
    \tensor*[^A]{\mathbf{f}}{}
  \end{matrix}\right)
  ,\quad
  \tensor*[^B]{\mathbf{X}}{^*_A}=\tensor*[^B]{\mathbf{X}}{^\top_A}=
    \left(\begin{matrix}
    \mathbf{E} & -\mathbf{E}\mathbf{r}\times \\
    \mathbf{0} & \mathbf{E}
  \end{matrix}\right)
\end{equation}

Note that except for the ordering of the translation and rotation
components, spatial vectors represent the same concepts as velocity,
acceleration and force wrenches, i.e. they both give a compact
representation of a vector field. In what follows, we only use the
spatial algebra notations.

In conclusion, the spatial vector notation provides a compact
rewriting of the dynamics equations, which leads to efficient dynamics
computation algorithms.

\subsection{Dynamics Equation}

\begin{figure}
  \centering
      {\def\svgwidth{0.4\linewidth}
        \subimport*{src/chap3-optimal-motion-planning/figure/}
                   {robot-dynamics.pdf_tex}
      }
      \caption{Non-vanishing and non-sliding contact forces are
        applied on the anthropomorphic system by its environment, and
        they are integrated in its dynamics equation. Joints limits
        are shown in red.}
      \label{fig:chap3-robot-dynamics}
\end{figure}

By using a Newtonian dynamics formulation, we can express the compact
dynamics equation for a floating-base robot with respect to the
generalized coordinate and actuated torque vectors $\mathbf{q}$ and
$\boldsymbol{\tau}$:

\begin{equation}
\label{dynamics-equation}
\mathbf{A}(\mathbf{q})\ddot{\mathbf{q}}
+\mathbf{b}(\mathbf{q},\dot{\mathbf{q}})
+\sum_k\mathbf{J}_{c_k}^\top\mathbf{f}^s_{c_k} =
\mathbf{S}^\top\boldsymbol{\tau},
\end{equation}

where $\mathbf{A}$ is the \emph{joint-space inertia matrix},
$\mathbf{b}$ is the joint-space bias force which account for both
Coriolis and gravity effects, $\mathbf{J}_{c_k}$ is the \emph{contact
  Jacobian} for the contact $c_k$ that is submitted to spatial contact
force $\mathbf{f}^s_{c_k}$. In this work, we assume that all bodies
are rigid and that contacts are non-sliding. This leads to the
necessary condition that each 3D contact force applied at a point must
lie inside the positive \emph{Coulomb friction cone}
\cite{trinkle1997dynamic} defined by the inequalities:

\begin{equation}
  \label{eq:chap3-friction-cone}
  \begin{array}{c}
    \mathbf{f}_{c_k}^{\top}\mathbf{u}_{c_k} \ge 0, \quad k=1,\dots,n_c, \\
    \norm{\mathbf{f}_{c_k}^\angle} \le
    \mu_s\norm{\mathbf{f}_{c_k}^\bot}, \quad k=1,\dots,n_c,
  \end{array}
\end{equation}

where $\mathbf{u}_{c_k}$ denotes the normal vector to the contact
surface, $\mathbf{f}^\bot$ and $\mathbf{f}^\angle$ denote the normal
and tangential contact forces to the contact surface respectively, and
$\mu_s$ denotes the \emph{limiting coefficient of static friction},
which depends of the contact interface nature (materials, temperature,
etc).

In addition to the dynamics equation, both of the actuators and the
kinematic structure can impose several limitations, such as joint
position limits

\begin{equation}
  \downbar{\mathbf{q}} \le \mathbf{q} \le \overbar{\mathbf{q}},
\end{equation}

joint velocity limits

\begin{equation}
  \downbar{\mathbf{\dot{q}}} \le \mathbf{\dot{q}} \le
  \overbar{\mathbf{\dot{q}}},
\end{equation}

and actuator torque limits

\begin{equation}
  \downbar{\boldsymbol{\tau}} \le \boldsymbol{\tau} \le
  \overbar{\boldsymbol{\tau}}
\end{equation}

These additional constraints, shown in Figure
\ref{fig:chap3-robot-dynamics} will also have to be taken into account
in the OCP formulation in order to generate feasible motions.

\subsection{Inverse Dynamics}

When the generalized position, velocity and acceleration vectors are
known, we can use the dynamics equation \ref{dynamics-equation} to
retrieve the unknown actuated torques $\mathbb{\tau}$. This is a
problem of \emph{inverse dynamics}; the \emph{Recursive Newton-Euler
  Algorithm (RNEA)} is an efficient algorithm which relies on a loop
of forward propagation of spatial velocities and accelerations
starting from the floating base, then a second loop of backward
propagation of torques and forces starting from the leaves of the
kinematic tree until the floating base. Its complexity is
$\mathcal{O}(n)$ and it has a low count of operations, which makes it
very suitable for optimal control applications.

\subsection{Forward Dynamics}

In \emph{Forward dynamics}, on the opposite of the inverse dynamics
problem, the generalized position, velocity and actuated torque
vectors are known, and the accelerations $\ddot{\mathbf{q}}$ are
unknown.

The \emph{Composite Rigid Body Algorithm (CRBA)} is an efficient
algorithm for computing the joint-space inertia matrix
$\mathbf{A}(\mathbf{q})$. Interestingly, the bias force
$\mathbf{b}(\mathbf{q},\dot{\mathbf{q}})$ can be retrieved by computing the
inverse dynamics while setting both accelerations $\ddot{\mathbf{q}}$
and contact forces $\mathbf{f}^s_{c_k}$ to $\mathbf{0}$. We can then
use standard linear algebra solvers to solve the following system for
$\ddot{\mathbf{q}}$:

\begin{equation}
  \mathbf{A}(\mathbf{q})\ddot{\mathbf{q}} =
  \mathbf{S}^\top\boldsymbol{\tau} -
  \mathbf{b}(\mathbf{q},\dot{\mathbf{q}}) -
  \sum_k\mathbf{J}_{c_k}^\top\mathbf{f}^s_{c_k}
\end{equation}

The whole algorithm complexity is $\mathcal{O}(n^3)$; the
\emph{Articulated Body Algorithm (ABA)}, just like RNEA, is based on a
propagation method and offers a complexity of $\mathcal{O}(n)$. As the
torques usually constitute the physical controls of a system, forward
dynamics algorithms are very useful in simulation and control
applications.

\subsection{Dynamic Balance for Anthropomorphic Systems}

Dynamic balance is a necessary condition to the generation of safe and
feasible motions. We describe here possible ways of including this
condition in an OCP.

\subsubsection{Dynamic Balance with Zero-Moment Point}

As we previously introduced the ZMP in Section \ref{subsec:chap1-zmp},
we simply recall that it provides a simple dynamic balance condition,
namely that the ZMP must remain inside the contact support polygon, as
long as the humanoid robot is moving on a flat floor. We saw in
Section \ref{subsec:chap1-cart-table} how it can be derived for the
cart-table model, and we briefly describe here a method to compute it
for whole-body motions of an anthropomorphic system using inverse
dynamics.

Let $\mathbf{q}$,$\dot{\mathbf{q}}$ and $\ddot{\mathbf{q}}$ denote
respectively the rigid-body system generalized position, velocity and
acceleration vectors. We recall that, if feasible contact forces are
applied to its bodies, a necessary and sufficient condition for a
humanoid robot dynamical balance is that it can realize the state
$\mathbf{q}$,$\dot{\mathbf{q}}$ and $\ddot{\mathbf{q}}$ using only its
physical actuators. As the humanoid robot does not have any thrusters,
this condition is equivalent to requiring that the 6D generalized
torque applied by the floating joint be 0:

\begin{equation}
\label{eq:chap3-dynamic-balance-inverse}
 \boldsymbol{\tau_{fl}}=\mathbf{0},
\end{equation}

where $\boldsymbol{\tau_{fl}}$ denotes the floating-joint torque
vector, see \cite{hirukawa2006universal}.

Conversely, if we set all contact forces to zero and we compute the
joint generalized torques using the RNEA, $\boldsymbol{\tau_{fl}}$
will be equivalent to a spatial force (or wrench): it is the force
that the floating joint would need to exert in order to make the whole
system realize the state given by $\mathbf{q}$,$\dot{\mathbf{q}}$ and
$\ddot{\mathbf{q}}$. This spatial force, expressed in the floating
base frame and denoted $\tensor*[^{fl}]{\mathbf{f}}{_c^s}$, is thus
equal to the resultant spatial force that includes all the necessary
contact forces. Computing the ZMP is then a simple matter of
transforming $\tensor*[^{fl}]{\mathbf{f}}{_c^s}$ to the absolute world
frame $W$, and finding the coordinates $(p_x,p_y)$ of the point on the
floor such that the moments around the $x$ and $y$ axes, i.e. the
first two components of $\tensor*[^W]{\mathbf{f}}{_c^s}$, are equal to
zero. This point $\mathbf{p}$ is, according to its definition, the
Zero-Moment Point which we are looking for. We can then guarantee a
humanoid robot dynamic balance by ensuring $\mathbf{p}$ stays inside
the support polygon $\mathcal{P}_{sup}$, i.e. the convex hull of all
contact points.

\subsubsection{Dynamic Balance with Non-Coplanar Contact Forces}

Let us briefly mention that the ZMP criterion is extended to handle
non-coplanar contact points such as arms and hands in
\cite{harada2003zmp}, and is called the \emph{Generalized ZMP
  (GZMP)}. An associated support polyhedron is defined, and the GZMP
must stay inside this polyhedron to ensure the dynamic balance of the
robot. Although this approach is interesting, it is not as simple as
the ZMP criterion, and we prefer to deal directly with contact forces
through the complete dynamics of the robot.

\paragraph{Forward Dynamics}

We present here a method that ensures the dynamic balance constraint
for optimal control, as seen in \cite{mombaur2005open}. It relies on
forward dynamics, where the system is torque-controlled. The state
contains both the acceleration $\ddot{\mathbf{q}}$ and contact forces
$\mathbf{f}^s_{c_k}$. 

As we work under the assumption that a contact point does not move
during the motion, we have:

\begin{equation}
\mathbf{p}_{c_k}(t)=\mathbf{p}_{c_k}(0),\quad k = 1,\ldots,n_c,
\end{equation}

where $\mathbf{p}_{c_k}$ denotes the 6D position of contact $c_k$.

By derivating it twice we obtain the contact condition:

\begin{equation}
\mathbf{J}_{c_k}\ddot{\mathbf{q}} +
\dot{\mathbf{J}}_{c_k}\dot{\mathbf{q}}=\mathbf{0}, \quad k = 1,\ldots,n_c,
\end{equation}

Let $\mathbf{f}^s_c$ and $\mathbf{J}_c$ denote the concatenated
contact force vector and contact Jacobian respectively:

\begin{equation}
\mathbf{f}^s_c=
\left(\begin{matrix}
\mathbf{f}^s_{c_1}\\
\vdots\\
\mathbf{f}^s_{c_k}\\
\vdots\\
\mathbf{f}^s_{c_{n_c}}\\
\end{matrix}\right),
\qquad
\mathbf{J}_c=
\left(\begin{matrix}
\mathbf{J}_{c_1}\\
\vdots\\
\mathbf{J}_{c_k}\\
\vdots\\
\mathbf{J}_{c_{n_c}}\\
\end{matrix}\right)
\end{equation}

The following linear system can then be built using the dynamics
equation and contact condition, and solved for $\ddot{\mathbf{q}}$ and
all $\mathbf{f}^s_{c_k}$.

\begin{equation}
  \left(\begin{matrix}
    \mathbf{A} & \mathbf{J}_{c}^\top \\
    \mathbf{J}_{c} & \mathbf{0}\\
  \end{matrix}\right)
  \left(\begin{matrix}
  \ddot{\mathbf{q}}\\
  \mathbf{f}^s_{c}
  \end{matrix}\right)
  = \left(\begin{matrix} \mathbf{S}^\top\boldsymbol{\tau}-\mathbf{b}
    \\ -\dot{\mathbf{J}}_{c}\dot{\mathbf{q}}
  \end{matrix}\right)
\end{equation}

%% The constraints $\mathbf{p}_{c_k}(t)=\mathbf{p}_{c_k}(0)$ and
%% $\dot{\mathbf{p}_{c_k}}(t)=\mathbf{0}$ also need to be enforced. 

Note that $\mathbf{J}_{c}$ must be full-rank, otherwise, the system is
not invertible. Therefore, this approach allows finding a unique set
of spatial forces as long as no more than one spatial contact force is
exerted on each rigid body. If we consider the humanoid walking case,
this means that one spatial contact force is applied on each
foot. However, the sum of the two solution forces can lead to a ZMP
lying outside the support polygon, as the foot geometry is never taken
into account. Solving the previous linear system is unfortunately not
always sufficient to ensure dynamic balance; additional constraints,
such as ZMP constraints \cite{koch2012optimization}, need to be added.

\paragraph{Inverse Dynamics}

We saw in Equation \equref{eq:chap3-dynamic-balance-inverse} that if
we apply feasible contact forces and the floating-joint torques are
zero, then the humanoid robot is dynamically balanced. If we chose to
control our system with the generalized acceleration vector
$\mathbf{\ddot{q}}$ and contact forces $\mathbf{f}^s_{c_k}$, we can
use a simple integration scheme to retrieve the generalized position
and velocity vectors $\mathbf{q}$ and $\mathbf{\dot{q}}$, compute the
torques $\boldsymbol{\tau}_{fl}$, and add Equation
\equref{eq:chap3-dynamic-balance-inverse} as an equality constraint in
the OCP formulation. This gives a way of integrating the dynamics and
enforcing the dynamic balance of the humanoid robot through a 6D
vector equality constraint, given any set of contact forces, even when
some of them are exerted on the same bodies. In order to ensure that
only feasible contact forces are applied, the inequalities from
Equation \equref{eq:chap3-friction-cone} also need to be taken into
account. A similar formulation, where the contact forces are
considered as optimization variables, was suggested in
\cite{saab-tro-12}.

\section{(Self-)Collision Avoidance}
\label{sec:chap3-collision-avoidance}

Beside generating dynamically feasible motions for an anthropomorphic
system, we need to make sure no collision occurs during the
motion. Let us assume a collision-free initial guess is fed to the OCP
solver. The optimization process iteratively reshapes motion and
collision between the robot and itself or the environment might
ensue. This motivates the need to take into account (self-)collision
avoidance in the OCP.

\subsection{Distance Pairs}

\begin{figure}
  \centering
      {\def\svgwidth{0.59\linewidth}
        \subimport*{src/chap3-optimal-motion-planning/figure/}
                   {robot-collision-pairs.pdf_tex}
      }
      \caption{All self-collision possible pairs are shown in red for
        body $B_i$. The collision pair between $B_i$ and an obstacle
        $O$ is also shown in blue.}
      \label{fig:chap3-robot-collision-pairs}
\end{figure}

Consider a body $B_i$ of the robot. Figure
\ref{fig:chap3-robot-collision-pairs} gives an idea of the potential
complexity of self-collision avoidance: if the robot has $N_B$ bodies,
there are $N_B-1$ potential pairs of bodies $\langle B_i,B_j\rangle$
that need to be checked at a given configuration $\mathbf{q}$ in order
to ensure that there is no collision between the robot bodies. Since
the pair $\langle B_i,B_j\rangle$ is equivalent to the pair $\langle
B_j,B_i\rangle$, the total number of self-collision body pairs can be
as high as to $\frac{N_B(N_B-1)}{2}$. Furthermore, assuming that the
obstacles surrounding the robot are considered as a single geometric
entity $O$, we also need to check $N_B$ body-environment pairs
$\langle B_i,O\rangle$ for collisions.

One could use efficient collision detection algorithms, but their
return result is Boolean and is not suitable for gradient-based
optimal control. In order to guarantee (self-)collision avoidance, we
need to compute the distance between for all potential collision pairs
(or distance pairs), and make sure this distance is positive during
the whole duration of the optimized motion.

\subsection{Distance Computation for Collision Avoidance}

A geometry can be represented accurately by a cloud of vertices, and a
set of facets, usually triangles, which define the surface of the
geometry. One could then express inequality constraints using the
exact distance between the polyhedral geometries. Thanks to bounding
volume hierarchy representations of the polyhedra, the distance
computation can be precise and relatively efficient \cite{Larsen2000},
especially when the algorithms are parallelized on graphics processing
unit (GPU) \cite{lauterbach2010gproximity}. However, such algorithms
return a constant zero distance when collisions occur, thus leading to
a zero gradient; this can be very prohibitive as numerical
optimization methods rely on the local constraint information to
generate feasible iterates. In \cite{Kim2002}, a penetration
computation algorithm is proposed, but computation times are still too
restrictive. 

One strategy to cope with poor performance and gradient
discontinuities is to consider bounding volumes that contain the exact
robot body geometries. As this is a conservative approach, some
motions such as ones involving fine object manipulation cannot be
generated. In most cases, however, this approach is suitable for a
variety of robotic applications a constitutes a good trade-off between
precision and computation time. In \cite{Escande2007} a nice solution
to this problem is described: they introduce \emph{Sphere-Torus
  Patches Bounding Volumes (STPBV)}, which are strictly convex
bounding volumes of the exact polyhedral body geometries; the returned
distance can be negative for slight collisions, and it is shown that
the distance between a STPBV and a convex mesh is always $C^1$. These
constraints are successfully used for self-collision avoidance in
posture optimization, and real-time control of a humanoid robot
\cite{Stasse2008}. Capsules, which are basically cylinders capped by
half-spheres, are slightly more conservative than STPBV, but offer an
even simpler way of computing distances: computing the distance
between two capsules is equivalent to computing the distance between
two segments and subtracting the segment radii. In \cite{Kanoun2011}
for instance, such bounding volumes are successfully used to avoid
self-collision for a humanoid robot in a real-time control
application.

We discuss here an important aspect of OCP solutions when using direct
methods, seen in Section \ref{subsec:chap3-direct-methods}. Indeed,
these methods are based on a transcription of the OCP into a
finite-dimensional NLP, through a grid discretization. Constraints are
also discretized over the trajectory duration, which means that they
are verified on the grid points, but not between them. In
\cite{lee2012accurate}, based on previous work for safe trajectory
optimization \cite{Lengagne2010}, capsules are used as bounding
geometries for each body; the minimum distance over each sub-interval
of the discretization grid is computed for all distance pairs, and
this minimum distance is required to stay positive. Interestingly,
this leads to a final optimized motion which is guaranteed to be
collision-free for any $t\in[0,T]$. So far this method has been
applied to implement self-collision avoidance, i.e. motions are
generated in the absence of obstacles.

We briefly present the signed distance transform
\cite{felzenszwalb2004distance}, which is an alternative method for
computing distances: assuming that the environment is static, an
offline voxelized grid can be built, and the minimum distance to the
obstacles is computed for each voxel. If there is a collision, the
distance is negative and is equal to the penetration depth. This
method allows fast distance computation for optimization algoritm, but
the voxel grid needs to be fine enough to allow acceptable gradient
computation through finite differentiation.

\section{Optimal Control Applications for Anthropomorphic Systems}

Over the past thirty years, optimal control techniques have been
successfully applied in the fields of Robotics, Biomechanics and
Computer Graphics. The problem of tracking a reference path while
minimizing time can for instance be modeled as an OCP and solved
thanks to state-of-the-art solvers, see
\cite{bobrow1985time,verscheure2009time,suleiman2010time}. In this
case, the initial path is assumed to be collision-free; as solving the
path tracking problem consists in applying a time parameterization
without deforming the path, collision avoidance constraints are not
taken into account.

Optimal control techniques can also be used for motion imitation such
as in \cite{suleiman2008human}, where trajectories are generated for a
humanoid robot by minimizing the error with reference human motions
and ensuring its dynamic balance. Self-collisions are then
post-processed when replaying the motion, using a task-based
controller for instance, see \cite{kanehiro2008local}.

In \emph{Model Predictive Control (MPC)}, the current control of a
system is derived from its future states to ensure its
stability. Finding the best control can be done through an optimal
control formulation over a receding time horizon, in order to ensure
maximum dynamic balance for instance. This has led to online control
applications for a biped walking motion of a humanoid robot
\cite{kaji03,herdt2010online}, and more complex locomotion on non-flat
terrains for animated avatars
\cite{coros2010generalized,tassa2012synthesis}.

From a biomechanics point of view, some aspects of human motion can be
represented as the resulting optimal policies of OCP. Conversely,
solving the same OCP can allow human behaviors to emerge from the
solutions: such behaviors include walking
\cite{chevallereau2001optimal}, running \cite{Schultz2010}, emotional
walking \cite{felis2012modeling} and even more general motions
involving seamless extreme locomotion and manipulation
\cite{mordatch2012discovery}. It is interesting here to point out the
gradual convergence of the Robotics, Biomechanics and Computer
Graphics fields as simulation models become more and more realistic
and are able to take into account various kinds of physical
interactions including gravity, actuator models, contact models, etc.

Some humanoid motions are very hard, or even impossible to generate
without optimal control methods. Indeed, dynamic motions greatly
expand the capabilities of humanoid robots which otherwise would have
to satisfy the more restrictive quasi-static balance
constraints. Complex motions such as ball-kicking
\cite{miossec2006development} and weight-lifting
\cite{arisumi2008dynamic}, and parkour \cite{dellin2012framework} can
then be obtained. Also, the accessible space of a humanoid robot can
be further increased if it uses its environment to help it achieve its
goal; this involves generating multiple non-coplanar contact motion,
and optimal control methods have proved to be very powerful tools to
do so \cite{lengagne2011generation}.

\bigskip

In many cases, robots have to move in the presence of
obstacles. Therefore we must make sure that the resulting optimal
policy does not lead to any collision between the robot and its
environment or even itself. In \cite{dubowsky1986time}, time-optimal
collision-free trajectories are computed for a 6-DoF manipulator by
adding, to the OCP objective function, a penalty term that computes
the distance to obstacles and allows avoiding them. Penalty terms
are also used in \textsc{CHOMP} \cite{ratliff2009chomp}, an efficient
optimal control solver which relies on a covariant gradient descent
technique, and in \textsc{STOMP} \cite{Kalakrishnan2011}, a similar
solver which relies on trajectory stochastic perturbations in order to
find collision-free optimal trajectories without computing function
Jacobians.

All previous applications involve simple robotic arms; in
\cite{Toussaint2007}, a humanoid robot trajectory is modeled as a
finite sequence of attractors in the task-space, such as a 3D hand
position. This allows a great dimension reduction of the underlying
NLP and leads to very short optimizations times of the order of a few
seconds. An obstacle avoidance penalty term is also added in the
objective function, and enables the robot to avoid both
self-collisions and collision with simple planar obstacles. In this
latter work, the initial trajectory can potentially generate
collisions, although there is no guarantee that the optimization
process will succeed in finding a collision-free solution in more
complex environments. Furthermore, as no contact body position or
dynamic balance tasks are considered, fast motions cannot be generated
with this framework without compromising the robot dynamic balance.

In the general case, minimizing an objective function which contains
constraints transcribed as penalty terms allows building unconstrained
optimal control problems. Good convergence rates can then be obtained
as long as the problem dimension is small, and as long as the sum of
too many penalty functions does not lead to an increased nonlinearity
of the objective function. Otherwise, the performance gain obtained by
solving an unconstrained NLP is neutralized by a poor convergence
rate. Furthermore, the sum of penalty terms is usually weighted to
give more or less importance to each term. This leads to the problem
of choosing the correct weights such that the resulting trajectory is
satisfactory for a variety of problems.

\bigskip

All methods cited above make profit from optimal control to achieve
several applications of motion generation. However, current
formulations either work under the assumption that the initial guess
is collision-free, or allow it to be slightly in collision by means of
linear interpolation between the initial and final states, without
giving any guarantee that the optimization process will succeed. In
fact, there are cases where the solver might get stuck in local minima
and fail to generate a trajectory that avoids collisions of the robot
with either itself or the environment.

\bigskip

The idea of combining planning algorithms with optimization methods is
not new, and is especially motivated by the wide use of sampling-based
planners which generally produce collision-free paths of poor-quality
\cite{lava06}. The shortcut method, which we used in Chapters 1 and 2,
can be seen as a local optimization method. In
\cite{geraerts2007creating}, several shortcut heuristics are developed
to increase a path quality and clearance from obstacles, but they can
be used to shorten a path length with respect to a given metric only
in the configuration space as time is not considered. A suitable
shortcut heuristic for optimal control of simple robotic arms is
described in \cite{hauser2010fast}: starting from an initial
collision-free path given by a RRT path, an initial trajectory is
placed on the path, making stops at the milestones to ensure it is
still collision-free, then a shortcut heuristic is called several
times to reduce the trajectory duration under bounded velocity and
acceleration constraints, while making sure the result is still
collision-free. Similarly, a method that combines a sampling-based
planner and the \textsc{STOMP} optimizer is proposed, see
\cite{mainprice2012planification}. Note that in both previous methods,
results were successfully obtained for simple 7-DoF arms; as they do
not allow enforcing complex constraints such as closed-loop
constraints or dynamic balance, achieving optimal motion planning for
anthropomorphic systems with such methods does not seem to be possible.

\section{Contribution}
\label{sec:chap3-contribution}

To our best knowledge there is no available algorithmic approach that
addresses the global problem of optimal motion planning for complex
robots, such as anthropomorphic systems, in the presence of
arbitrarily complex obstacles.

We therefore propose a new framework for optimal motion
planning. Given a humanoid robot geometric and dynamic model, an exact
model of the environment, start and end configurations, and a robot
contact stance, we first \emph{plan} a collision-free \emph{statically
  balanced} path that satisfies all kinematic constraints. We use the
constrained RRT planner, which we presented in Section
\ref{subsec:chap1-sampling-algorithms}, to this end. We convert the
path to an initial trajectory using a suitable time parameterization,
and we then \emph{optimize} it to generate a locally-optimal
collision-free \emph{dynamically-balanced} trajectory. The
\textsc{MUSCOD-II} solver uses a direct multiple shooting method to
solve the formulated optimal control problem. Note that this involves
both finding a new time parameterization for the trajectory, and
reshaping the path in a geometrical sense, so it is not simply a
problem of optimal path tracking.

In order to ensure (self-)collision avoidance, we choose to model
distance constraints using bounding capsules around the robot exact
body geometries. In previous applications, the capsule parameters were
set by hand by the user for a given body. We therefore provide an
automatic bounding capsule generation tool; it relies on a NLP
formulation that allows us to find the minimum-volume capsules around
bodies which are modeled by polyhedra. The capsules allow us then to
enforce collision-avoidance constraints between the robot, obstacles
and itself.

To ensure dynamic balance during the robot motion, most of the results
we present on the ZMP criterion; we introduce later on some
preliminary results when using a multiple contact force formulation.

The full framework is successfully applied to generate optimal
collision-free trajectories for a humanoid robot both in simulation
and on the HRP-2.

The collision avoidance constraints are tackled in Section
\ref{distance-constraints} and used in the optimal control problem
described in Section \ref{sec:chap3-omp-framework}. Section
\ref{results} showcases results obtained for the robot HRP-2. We also
show an extension to multiple contact points in Section
\ref{sec:chap3-noncoplanar-contact-points}.

\section{(Self-)Collision Avoidance Constraints}
\label{distance-constraints}

Before providing a description of our optimal motion planning
framework, we first focus in this section on building the collision
avoidance constraints through the automatic generation of bounding
capsules around the robot body geometries, and the automatic pruning
of unnecessary distance pairs $\langle B_i,B_j\rangle$ and $\langle
B_i,O\rangle$.

\subsection{Computing minimum bounding capsules}

Capsule can be represented as the union of a cylinder and two
half-spheres, or sphere-swept segment. It is uniquely determined by
its two segment endpoints $\mathbf{e_1}$, $\mathbf{e_2}$ and its
radius $r$. Capsules are convex geometries, and have been widely used
in Robotics and Computer Graphics as they provide a simple
representation of more complex polyhedral geometries.

In \cite{Kanoun2011}, the bounding capsules parameters are set by hand
to obtain the best fitting capsules around the body geometries, which
is not very practical especially if we want to use various robot
geometric models. In \cite{eberly20073d}, a method is proposed to
compute a bounding capsule of a set of vertices, but not necessarily
the best fitting one. This method is based on first determining the
capsule segment direction using a least-squares regression, setting
the capsule radius by finding the farthest vertex from the line, and
finally determining the segment length by trying to make the capsule
spherical caps come as close as possible to each other.

We propose here to automatically find minimum-volume capsule
parameters by solving, offline and once for each body of the robot,
the following optimization problem:

\begin{equation}
  \min_{\mathbf{e_1}, \mathbf{e_2}, r} \ \ 
  \|\mathbf{e_2} - \mathbf{e_1}\| \pi r^2 + \frac{4}{3}\pi r^3
  \label{capsule-objective}
\end{equation}
\ \ \ subject to:
\begin{equation}
  \begin{array}{rcll}
    r - d(\mathbf{\mathbf{v}},\mathbf{e_1e_2}) & \ge & 0\mbox{, for all }
    \mathbf{v} \in \mathcal{P},
    \label{capsule-constraint}
  \end{array}
\end{equation} 

where $d(\mathbf{p},\mathbf{e_1e_2})$ is the distance of $\mathbf{p}$
to line segment $\mathbf{e_1e_2}$.  Equations \ref{capsule-objective}
and \ref{capsule-constraint} mean we want to find the minimum-volume
capsule while ensuring all vertices $\mathbf{v}$ of the underlying
polyhedron $\mathcal{P}$ lie inside the capsule.

The problem we defined above is a NLP with inequality constraints. It
can be solved using either SQP or IPM methods, as long as we give
suitable initial parameters $\mathbf{e_1}_0$, $\mathbf{e_2}_0$, and
$r_0$. Luckily, a good initial guess can be provided by the bounding
capsule method we presented earlier, as all constraints are satisfied
and the initial volume is not far off the optimal volume.

It can be proved that a convex geometry is a bounding volume of a set
of points $\mathcal{P}$ if and only if it is a bounding volume of its
convex hull $\mathcal{H}_{\mathcal{P}}$, which is characterized by a
lower vertex count than $\mathcal{P}$. We can use this property to our
advantage: by first computing the convex hull and finding the
minimum-volume capsule for $\mathcal{H}_{\mathcal{P}}$, we are sure to
have better optimization performance as the number of constraints is
greatly reduced, especially for non-convex geometries.

We implement our minimization problem with RobOptim \cite{roboptim,
  moulard2012optimisation} and the \textsc{IPOPT} solver
\cite{Biegler2009}, and we use our implementation\footnote{An
  open-source implementation can be found at
  \url{https://github.com/roboptim/roboptim-capsule/} and
  \url{http://roboptim.net/roboptim-capsule/doxygen/1.0.1/}} to find
the optimal bounding capsules for both HRP-2 and Romeo \cite{romeo10}
humanoid robots. Table \ref{tab:chap3-minimum-capsule} demonstrates
how solving optimization problem instances for
$\mathcal{H}_\mathcal{P}$ instead of $\mathcal{P}$ accelerates their
convergence. Figures \ref{fig:chap3-hrp2-capsule} and
\ref{fig:chap3-romeo-capsule} show the best fitting bounding capsules
superimposed over the original robot geometries.

\begin{table}
  \renewcommand{\arraystretch}{1.3}
  \caption{Performance of minimum-volume bounding capsules generation.}
  \label{tab:chap3-minimum-capsule}
  \centering
  \begin{tabular}{|c|C{0.11\linewidth}|C{0.2\linewidth}|C{0.18\linewidth}|C{0.18\linewidth}|}
    \hline
    Robot & Body count & Mean vertex count per body & Total computation time without convex hull (s) & Total computation time using convex hull (s) \\
    \hline
    HRP-2 & 41 & 1526 & 46.8 & 7.50 \\ 
    \hline
    Romeo & 46 & 7033 & 410 & 27.6 \\
    \hline
  \end{tabular}
\end{table}

\begin{figure}
  \centering
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/hrp2-full-mesh.png}
    \caption{Original geometries.}
    \label{simple-patha}
  \end{subfigure}
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/hrp2-convex-hull.png}
    \caption{Convex hull.}
    \label{simple-path-sola}
  \end{subfigure}
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/hrp2-bounding-capsule.png}
    \caption{Initial capsule parameter guess.}
    \label{capsulea}
  \end{subfigure}
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/hrp2-capsule.png}
    \caption{Optimization result.}
    \label{simple-path-sol-shortcuta}
  \end{subfigure}
  \caption{Minimum-volume bounding capsule generation for the HRP-2.}
  \label{fig:chap3-hrp2-capsule}
\end{figure}

\begin{figure}
  \centering
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/romeo-full-mesh.png}
    \caption{Original geometries.}
    \label{simple-pathb}
  \end{subfigure}
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/romeo-convex-hull.png}
    \caption{Convex hull.}
    \label{simple-path-solb}
  \end{subfigure}
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/romeo-bounding-capsule.png}
    \caption{Initial capsule parameter guess.}
    \label{capsuleb}
  \end{subfigure}
  \begin{subfigure}{0.24\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/romeo-capsule.png}
    \caption{Optimization result.}
    \label{simple-path-sol-shortcutb}
  \end{subfigure}
  \caption{Minimum-volume bounding capsule generation for the Romeo
    robot.}
  \label{fig:chap3-romeo-capsule}
\end{figure}

\subsection{Computing Distances for Pairs}

The optimal capsule parameters can now be used to compute distances
for body-body and body-environment pairs. With respect to body-body
distance pairs, we can compute their minimum distance by first
computing the distance between the two capsule segments, then subtract
their radii in order to obtain the real distance. We rely on the Wild
Magic geometric library \cite{schneider2003geometric, wildmagic} to
compute this distance in an average time of 2 $\mu$s.

Concerning capsule-environment pairs, as the environment is modeled by
polyhedral meshes, we can compute their distance by computing the
distance between the capsule segment and mesh, then subtract the
capsule radius. State-of-the-art distance computation algorithms rely
on building a hierarchical tree of simple bounding volumes around the
mesh. In our work, we rely on an implementation of OBB-Trees in the
Kineo Collision Detection (KCD) library to compute distances for
capsule-environment pairs. For the environment in figure \ref{path},
the distance for one capsule-environment pair takes about 500 $\mu$s
to be computed, since the environment is assumed to be perfectly
modeled by polyhedron meshes. Note that even for very efficient
implementations, the tree traversal scheme in bounding volume
hierarchies implies running multiple proximity queries and we cannot
hope for good performance unless GPU-based implementations are used.

\subsection{Body Distance Pair Selection}

We mentioned in Section \ref{sec:chap3-collision-avoidance} that if we
were to take into account all body distance pairs of a robot, we could
end up with $\frac{N_B(N_B - 1)}{2}$ possible pairs. This means that
for a robot like HRP-2 with 41 bodies, we can have up to 820 pairs and
it can be very costly to evaluate the distance for all of
them. Luckily, some bodies are either always colliding because they
are adjacent in the kinematic tree, or never colliding due to
kinematic constraints; for the particular example of the HRP-2, its
kinematic tree and joint limits are such that the head body can never
collide with its chest or any of its feet. The pairs corresponding to
those bodies can therefore be safely pruned.

In order to avoid hand-checking of all pairs, we use the offline tool
implemented in \cite{planning-environment}: it relies on finely
exploring the configuration space, using a sampling-based planner such
as RRT, and keeping track of colliding bodies. In the case of the
HRP-2, this allows us to keep only 510 ``useful'' pairs out of 820
pairs. Although not used in this work, note that there exist online
collision pair pruning techniques which allow to accelerate collision
detections and proximity queries \cite{ericson2004real}.

As in all our examples, we consider the particular case of
double-support motion, we can be sure that most of the leg bodies
cannot collide with each other due to the additional kinematic
constraints. This is a manual step, but it could be automated if
additional kinematic constraints were taken into account in the
previously described tool. We finally end up with 327 capsule-capsule
pairs that must be all evaluated to guarantee self-collision
avoidance.

Similarly, we can do more effort and prune some of the
capsule-environment pairs that do not need to be checked due to the
particular kinematic structure of a robot. In the case of HRP-2 for
instance, if both waist and chest are not in collision with the
environment, we can be sure that it will be the same for the
intermediate body linking them. This case is not handled in the
automated tool. Out of 41 potential capsule-environment pairs, we keep
23 pairs.

\section{Optimal Motion Planning Framework}
\label{sec:chap3-omp-framework}

Now that we have defined collision avoidance constraints, we can build
the full optimal motion planning framework. It can be decomposed into
two main stages, namely constrained path planning and optimal control,
with an intermediate stage which builds a time parameterization over
the path that is generated by the planner.

In our work, we focus on generating collision-free trajectories for
the HRP-2 in the case both its feet remain in the same position on a
horizontal floor. We choose to minimize the integral, over a fixed
duration, of the generalized square jerk $\dddot{\mathbf{q}}(t)$; this
helps obtain smooth motions.

\subsection{Constrained Path Planning}
\label{subsec:chap3-path-planning}

\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]
                {src/chap3-optimal-motion-planning/figure/shelves-path.png}
\caption{Path found by the path planner in a shelves environment.}
\label{path}
\end{figure}

We use the constrained planner in \cite{dalibard09}, which we
described in Section \ref{subsec:chap2-constraint-motion-planning},
and which is implemented with the motion planning library
KineoWorks\texttrademark \cite{laumond2006kcs}. This planner allows
generating a collision-free path, while guaranteeing that the solution
path lies on a manifold of the configuration space. We want to
generate for HRP-2 a collision-free path that guarantees its
quasi-static balance when it is standing on both feet. We then define
the manifold $\manifold$ with the following stack of equality
constraints:

\begin{enumerate}
  \item Right foot has a fixed 6D transformation,
  \item Left foot has a fixed 6D transformation,
  \item Center of mass vertical projection lies in the center of the
    support polygon.
\end{enumerate}

Additionally, we would like to avoid choosing a single goal
configuration \config{g}, but instead define a goal task
\task{g}. This task can be defined by a sub-manifold
$\goalmanifold$\thinspace of the planning manifold $\manifold$. For a
simple object manipulation task, $\goalmanifold$\thinspace can be
defined as the intersection between $\manifold$\thinspace and the
manifold defined by the following stack of equality constraints:

\begin{enumerate}
  \item Gripper has the same 3D position as the object to grab.
  \item Gripper thumb is oriented vertically.
\end{enumerate}

Given a start configuration \config{s} a planning manifold $\manifold$
and a goal sub-manifold $\goalmanifold$, we first create a set of goal
configurations \config{g} by sampling a fixed number of configurations
in $\goalmanifold$, then we solve the path problem from \config{s} to
\config{g}. The constrained planner diffuses trees from \config{s} and
each configuration of \config{g}, and stops once at least one of the
goal configurations is in the same connected component as
\config{s}. A shortcut optimizer can then prune unnecessary waypoints
and shorten the solution path. Figure \ref{path} shows an example
where HRP-2 has to grab an object on the lower shelf and place it on
the upper shelf.

\subsection{Time Parameterization for Initial Trajectory}
\label{subsec:chap3-time-parameterization}

The constrained path planner generates a collision-free statically
balanced path where the kinematic constraints are enforced, but we
still need to apply a time parameterization before feeding it to the
optimal control solver. We want to minimize the sum of square jerks;
it is shown in \cite{Flash1985} that an unconstrained minimum-jerk
trajectory is a polynomial of degree 5 which can be explicitly
computed if the initial and final states are known. We choose then to
place minimum-jerk trajectories between each pair of path waypoints,
assuming they start and end at zero velocity and acceleration. This
ensures that the configuration $\mathbf{q}(t)$ follows exactly the
solution path and that collision avoidance constraints are not
violated around the waypoints.

As we rely on a direct multiple-shooting optimal control solver, the
minimum-jerk trajectories that have been computed are discretized
along the state and control grid. Figure \ref{fig:chap3-time-param}
shows an example where the time grid has 20 sub-intervals and a
duration of 2 seconds, the control is a piecewise linear function
representing the jerk, and the state is comprised of the position,
velocity and acceleration. Note that as only the nodes $\mathbf{s}_i$
are known, the remainder of the state trajectory can be obtained using
the control representation and successive time integrations.

\begin{figure}
  \centering
  \begin{subfigure}{0.5\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {dddq.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.49\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {ddq.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.49\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {dq.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.5\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {q.pdf_tex}
          }
        }
  \end{subfigure}
  \caption{In this example, the planned path contains 5
    milestones. The jerk (in orange) is a continuous piecewise linear
    function, and is computed such that the position trajectory starts
    and ends with zero velocity and acceleration at each
    milestone. The state nodes (blue dots) are similarly chosen, and
    the controls are integrated over each sub-interval to obtain the
    full trajectory (in blue). Note that discontinuities are observed
    because of the control parameterization.}
  \label{fig:chap3-time-param}
\end{figure}

\subsection{Optimal Control Problem Formulation}
\label{subsec:chap3-ocp}

We can now build the full OCP formulation, and let the optimization
solver reshape the initial guess in order to minimize the objective
function while enforcing all constraints. This should lead to smooth
motions without intermediate stops.

\subsubsection{Objective function}

We choose to minimize, for a fixed duration, the integral over time of
the sum of square jerks, as this criterion leads to smooth trajectories.

The objective function can then be written as:
\begin{equation}
  J = \int_{0}^{T}\mathbf{\dddot{q}}(t)^T\mathbf{\dddot{q}}(t) dt
  \label{objective-function}
\end{equation}

and we define the state and control variables to be:
\begin{equation}
  \begin{array}{rcl}
  \mathbf{x}(t) & = & [\mathbf{q}(t), \mathbf{\dot{q}}(t), \mathbf{\ddot{q}}(t)]^T \\
  \mathbf{u}(t) & = & [\mathbf{\dddot{q}}(t)]^T
  \end{array}
  \label{variables}
\end{equation}

\subsubsection{Equality and inequality constraints}

\paragraph{Joint constraints}
Each actuated joint is subject to physical limitations of its
underlying actuator and mechanical structure. Box constraints on
angular, speed and torque limits are then added as:

\begin{equation}
  \begin{array}{rcccl}
    \downbar{\mathbf{q}} & \le & \mathbf{q} & \le & \overbar{\mathbf{q}} \\
    \downbar{\mathbf{\dot{q}}} & \le & \mathbf{\dot{q}} & \le & \overbar{\mathbf{\dot{q}}} \\
    \downbar{\boldsymbol{\tau}} & \le & \mathbf{\tau} & \le & \overbar{\boldsymbol{\tau}}
  \end{array}
  \label{joint-constraints}
\end{equation}

\paragraph{Dynamic balance}
The robot is submitted in our case to multiple coplanar contact
reaction forces from the ground. We can then express the dynamic
balance constraint using the whole-body ZMP, which has to remain
inside the robot support polygon defined by its feet.

These constraints can be written as for any $t\in[0,T]$:
\begin{equation}
  \begin{array}{rcl}
    \mathbf{p}_{lf}(\mathbf{q}(t)) & = & \mathbf{p_{lf}}(\mathbf{q}(0)) \\
    \mathbf{p}_{rf}(\mathbf{q}(t)) & = & \mathbf{p_{rf}}(\mathbf{q}(0)) \\
    \mathbf{p}_{zmp} (\mathbf{q}(t), \mathbf{\dot{q}}(t), \mathbf{\ddot{q}}(t)) & \in & \mathcal{P}_{sup},
  \end{array}
  \label{dynamic-constraints}
\end{equation}

where $\mathbf{p}_{lf}$, $\mathbf{p}_{rf}$ are respectively the 6D
positions of the left and right foot, $\mathbf{p}_{zmp}$ and
$\mathcal{P}_{sup}$ are the 2D ZMP coordinates and the support polygon
respectively. Note that in order to ensure $\mathbf{p}_{lf}$ and
$\mathbf{p}_{rf}$ are continuous functions, we do not use Euler angles
(such as roll, pitch and yaw) to represent 3D rotations, and each
contact body position is written as the concatenation of a 3D
translation vector and a 3D rotation vector; the rotation vector
direction gives the rotation axis, and its norm gives the rotation
angle around this axis.

\paragraph{Collision avoidance constraints}
We use the capsule-capsule and capsule-environment pairs defined in
Section \ref{distance-constraints}. Given a configuration \config{} of
the robot, we check that distances for pairs of bodies and pairs of
body and obstacle are positive to ensure (self-)collision
avoidance. We first tried to add one constraint per pair, which added
up to $(327 + 23)*n_{ms}$ constraints, where $n_{ms}$ is the number of
shooting nodes in \textsc{MUSCOD-II}. This led to poor performance as
the solver systematically went beyond the threshold number of
iterations. We hence propose to define one inequality constraint per
robot body, with its value being the minimum distance for all distance
pairs involving this body, i.e. both self-collision and obstacle
collision pairs.

\section{Results}
\label{results}

\begin{figure}
  \centering
  \begin{subfigure}{0.32\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/simple-path.png}
    \caption{Initial invalid path.}
    \label{simple-path}
  \end{subfigure}
  \begin{subfigure}{0.32\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/simple-path-sol.png}
    \caption{RRT path.}
    \label{simple-path-sol}
  \end{subfigure}
  \begin{subfigure}{0.32\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/simple-path-sol-shortcut.png}
    \caption{Shortcut path.}
    \label{simple-path-sol-shortcut}
  \end{subfigure}
  \caption{Paths for the test case.}
\end{figure}

We demonstrate the effectiveness of our optimal motion planning
framework by first using it in a a simple test case example, then
applying it to generate feasible motions on the robot HRP-2. All tests
were run on a computer with a 2.53 GHz
Intel\textsuperscript{\textregistered} Core\texttrademark2 Duo
processor.

\subsection{Test Case}
\label{test-case}
Figure \ref{simple-path} shows the motion planning problem to be
solved: HRP-2 starts from its rest position and moves to a goal
configuration by raising its left arm. A concave object is placed such
that the left hand is at one point enclosed in it if the initial path
connecting the start to goal configuration is executed. This is a
typical example of a problem with a local minimum defined by the
environment, where a real-time control approach in task-space might
fail. Figure \ref{simple-path-sol} shows a possible solution path
found with constrained RRT. This path can be shortened with a shortcut
optimizer, as in figure \ref{simple-path-sol-shortcut}.

To showcase the usefulness of our approach, we try to solve the
optimal control problem defined in Section \ref{subsec:chap3-ocp}
starting from the different paths, and put all results in Table
\ref{table}. When starting with the initial path from figure
\ref{simple-path}, the solver failed to achieve a single
iteration. This can be explained by the fact that in the middle of
this path, the robot left hand is enclosed inside the obstacle and
some distance constraints are violated; the solver fails to determine
a clear direction which would remove this violation due to the
geometric local minimum. Since the constrained RRT avoids it and
generates a collision-free path, the solver behaves correctly when
starting with the path in \ref{simple-path-sol}, but the maximum
number of iterations is reached before reaching convergence. It is
achieved when starting with the shortcut path in
\ref{simple-path-sol-shortcut}.  

\begin{table}
  \renewcommand{\arraystretch}{1.3}
  \caption{Test Case Computation Times}
  \label{table}
  \centering
  \begin{tabular}{|c||c|c|c|}
    \hline
    Initial guess & Initial path & RRT path & Shortcut path \\
    \hline
    Planning time (s) & -- & 5 & 5 \\
    \hline
    Shortcut time (s) & -- & -- & 4 \\
    \hline
    Optimization status & ERROR & MAX\_ITER & OK \\
    \hline
    SQP iterations & -- & 200 & 70 \\
    \hline
    Optimization time (s) & -- & 3068 & 1186 \\
    \hline
    Constraints evaluation time (s) & -- & 2176 & 847 \\
    \hline
  \end{tabular}
\end{table}

In Figure \ref{fig:chap3-zmp-2s-final-ux}, the evolution of the same
component for the generalized position, velocity, acceleration and
jerk is shown. We can see that the state trajectory is continuous,
smooth, and the intermediate stops that were present in the initial
guess have disappeared.

\begin{figure}
  \centering
  \begin{subfigure}{0.49\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {zmp-2s-final-dddq.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.5\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {zmp-2s-final-ddq.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.49\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {zmp-2s-final-dq.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.5\columnwidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {zmp-2s-final-q.pdf_tex}
          }
        }
  \end{subfigure}
  \caption{Test case: optimized position, velocity, acceleration and
    jerk trajectories for the chest yaw joint. Note that compared to
    Figure \ref{fig:chap3-time-param}, there are no more intermediate
    stops and the trajectories are smooth.}
  \label{fig:chap3-zmp-2s-final-ux}
\end{figure}

Figure \ref{fig:chap3-zmp-2s-final-p} shows the evolution of all 12
components of the kinematic equality constraints on both feet. As the
constraints are only enforced on the shooting nodes, we observe slight
deviations on the sub-intervals; they are luckily sufficiently small
to consider these constraints as perfectly enforced.

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {zmp-2s-final-p.pdf_tex}
        }
      }
  \caption{Test case: evolution of kinematic constraint values over
    time. As we constrain the 6D positions of the two robot feet, we
    end up with 12 equality constraints. They are only fully enforced
    on the shooting nodes, but it can be seen that the maximum
    deviation does not exceed a few $\mu$m.}
  \label{fig:chap3-zmp-2s-final-p}
\end{figure}

Note that about 70\% of the optimization time is spent in evaluating
the distance constraints and their gradients; this significant
overhead can be explained by the fact that \textsc{MUSCOD-II} relies
on internal numerical differentiation to compute Jacobians. Figure
\ref{fig:chap3-zmp-2s-final-d} shows the evaluation of the collision
avoidance constraints: due to the time discretization, one constraint
is violated during less than 100ms. This violation does not however
exceed 1mm, and this is considered as acceptable as all distance
constraints are computed with bounding capsule geometries which
already define conservative volumes around the exact geometries.

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {zmp-2s-final-d.pdf_tex}
        }
      }
  \caption{Test case: Evolution of the distance inequality constraint
    values over time. As the constraints are only enforced at the
    shooting nodes, a slight penetration of a maximum of 1mm is
    observed between the left forearm capsule and the obstacle.}
  \label{fig:chap3-zmp-2s-final-d}
\end{figure}

Finally, we observe in Figure \ref{fig:chap3-zmp-2s-final-zmp} that
dynamic balance is guaranteed during the whole motion, as the ZMP
remains fully inside the support polygon.

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {zmp-2s-final-zmp.pdf_tex}
        }
      }
  \caption{Test case: Trajectory of the ZMP and the CoM vertical
    projection on the floor. The green rectangles correspond to the
    robot left and right foot, and the filled area is the support
    polygon. As the ZMP never goes out the support polygon, this
    trajectory is dynamically balanced.}
  \label{fig:chap3-zmp-2s-final-zmp}
\end{figure}

\subsection{Dynamic Motion Generation on the HRP-2}

We also use our approach to generate fast optimal collision-free
trajectories and execute them on the humanoid robot HRP-2. In the
first scenario, HRP-2 executes a kind of martial art figure where it
crosses its arms rapidly while bending its knees, changes the arms
configuration, then moves back to a rest posture. The motion must be
executed while ensuring the arms do not collide with each other, and
the robot does not fall. This is quite a difficult task as the 3
trajectories durations are fixed to 1, 2, and 2 seconds
respectively. Particularly, the second motion where one arm goes from
being behind the other arm to being ahead of it proved to be
impossible to generate without a prior planning phase as proposed in
out approach.

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {karate-zmp-2s-final-d.pdf_tex}
        }
      }
  \caption{Martial arts scenario, phase 2: evolution of the distance
    inequality constraint values over time. A slight penetration of a
    maximum of 3mm is observed between the left and right forearm
    capsules.}
  \label{fig:chap3-karate-zmp-2s-final-d}
\end{figure}

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {karate-zmp-2s-final-zmp.pdf_tex}
        }
      }
  \caption{Martial arts scenario, phase 2: trajectory of the ZMP and
    the CoM vertical projection on the floor. The green rectangles
    correspond to the robot left and right foot, and the filled area
    is the support polygon. As the ZMP never goes out the support
    polygon, this trajectory is dynamically balanced.}
  \label{fig:chap3-karate-zmp-2s-final-zmp}
\end{figure}

In the second scenario, we add a complex environment that contains
shelves with different levels; HRP-2 first bends its knees to grab a
ball located deep on the lower shelf, then moves it to an upper shelf
to release it between two other objects. The trajectories last
respectively 2 and 5 seconds. Here, both collision and self-collision
constraints need to be enforced in order to obtain a valid
trajectory. Again, the ball transfer motion cannot be generated using
an optimal control solver and a simple initial guess; a prior planning
phase is needed to find a collision-free transfer path.

\begin{figure}
  \centering
  \begin{subfigure}{0.49\linewidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {grasping-zmp-2s-final-zmp.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {grasping-zmp-2s-final-point8zmp-zmp.pdf_tex}
          }
        }
  \end{subfigure}
  \caption{Shelves scenario, phase 2: trajectories of the ZMP and the
    CoM vertical projection on the floor. Left: the dynamic balance
    constraints are enforced at the nodes, but the ZMP goes out the
    support polygon in two sub-intervals. Right: the ZMP stays inside
    the support polygon when more restrictive balance constraints and,
    leading to a reduced support polygon, are used.}
  \label{fig:chap3-grasping-zmp-2s-final-zmp}
\end{figure}

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {grasping-zmp-2s-final-d.pdf_tex}
        }
      }
  \caption{Shelves scenario, phase 2: evolution of the distance
    inequality constraint values over time. A slight penetration of a
    maximum of 3mm is observed between the right gripper capsule and
    the shelves.}
  \label{fig:chap3-grasping-zmp-2s-final-d}
\end{figure}

We successfully apply our framework to generate feasible motions for
both scenarios as seen in figures \ref{self-collision} and
\ref{shelves}. Computation times are shown in Tables
\ref{table-martial-art} and \ref{table-shelves}. Figures
\ref{fig:chap3-karate-zmp-2s-final-d} and
\ref{fig:chap3-grasping-zmp-2s-final-d} show the collision avoidance
constraint evolution for the second phase of each scenario. The ZMP is
plotted in Figure \ref{fig:chap3-karate-zmp-2s-final-zmp} for the
martial arts scenario. In the shelves scenario, Figure
\ref{fig:chap3-grasping-zmp-2s-final-zmp}, left, shows that the ZMP
inequality constraint which corresponds to the front edge of the feet
is active at three nodes; as this constraint is not necessarily
enforced on the sub-intervals, it is violated, and this leads to a
fall of the robot. One solution would be to increase the trajectory
execution time so that the ZMP is closer to the CoM projection. As we
still want to generate fast motions, it is necessary to implement
balance constraints with a reduced support polygon to ensure that the
ZMP remains entirely inside the convex hull of the foot contact
points, even inside the time sub-intervals, see Figure
\ref{fig:chap3-grasping-zmp-2s-final-zmp}, right.

\begin{figure}
  \centering
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-1.png}
    \label{self-collision-1}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-2.png}
    \label{self-collision-2}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-3.png}
    \label{self-collision-3}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-4.png}
    \label{self-collision-4}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-5.png}
    \label{self-collision-5}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-6.png}
    \label{self-collision-6}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-7.png}
    \label{self-collision-7}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-8.png}
    \label{self-collision-8}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-9.png}
    \label{self-collision-9}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/self-collision-10.png}
    \label{self-collision-10}
  \end{subfigure}
  \caption{HRP-2 does a quick martial arts motion while avoiding
    self-collision.}
  \label{self-collision}
\end{figure}

\begin{figure}
  \centering
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-1.png}
    \label{shelves-1}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-2.png}
    \label{shelves-2}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-3.png}
    \label{shelves-3}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-4.png}
    \label{shelves-4}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-5.png}
    \label{shelves-5}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-6.png}
    \label{shelves-6}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-7.png}
    \label{shelves-7}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-8.png}
    \label{shelves-8}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-9.png}
    \label{shelves-9}
  \end{subfigure}
  \begin{subfigure}{0.19\columnwidth}
    \centering
    \includegraphics[width = \columnwidth]
                    {src/chap3-optimal-motion-planning/figure/shelves-10.png}
    \label{shelves-10}
  \end{subfigure}
  \caption{HRP-2 bends down quickly to grab a ball in the lower
    shelf and transfers it to the upper shelf.}
  \label{shelves}
\end{figure}

\begin{table}
  \renewcommand{\arraystretch}{1.3}
  \caption{Computation Times for Martial Arts Scenario}
  \label{table-martial-art}
  \centering
  \begin{tabular}{|c||c|c|c|}
    \hline
    Phase & 1 & 2 & 3 \\
    \hline
    Planning time (s) & 4 & 13 & 2 \\
    \hline
    Shortcut time (s) & 4 & 6 & 1 \\
    \hline
    SQP iterations & 32 & 73 & 25 \\
    \hline
    Optimization time (s) & 346 & 1130 & 278 \\
    \hline
    Constraints evaluation time (s) & 124 & 356 & 83 \\
    \hline
  \end{tabular}
\end{table}

\begin{table}
  \renewcommand{\arraystretch}{1.3}
  \caption{Computation Times for the Shelves Scenario}
  \label{table-shelves}
  \centering
  \begin{tabular}{|c||c|c|}
    \hline
    Phase & 1 & 2 \\
    \hline
    Planning time (s) & 13 & 38 \\
    \hline
    Shortcut time (s) & 6 & 23 \\
    \hline
    SQP iterations & 74 & 80 \\
    \hline
    Optimization time (s) & 1745 & 5020 \\
    \hline
    Constraints evaluation time (s) & 1396 & 2640 \\
    \hline
  \end{tabular}
\end{table}

\section{Extension to Non-Coplanar Contact Points}
\label{sec:chap3-noncoplanar-contact-points}

While the previous OCP allows us to successfully generate optimal
collision-free trajectories, it is limited to the case where all
contact points lie on the same plane, which allows us to ensure
dynamic balance through ZMP constraints. We propose to extend our
framework in order to handle dynamic balance with potentially
non-coplanar contact points and provide some preliminary results.

Therefore, we modify our formulation a bit by keeping the state vector
and adding to the control vector all 3D contact forces which are
applied on the robot bodies:

\begin{equation}
  \begin{array}{rcl}
  \mathbf{x}(t) & = & [\mathbf{q}(t), \mathbf{\dot{q}}(t), \mathbf{\ddot{q}}(t)]^T \\
  \mathbf{u}(t) & = & [\mathbf{\dddot{q}}(t), \mathbf{f}_c(t)]^T,
  \end{array}
  \label{variables-contact-point}
\end{equation}

and discretize the forces to represent them as continuous piecewise
linear function, as for jerks. Each 3D force vector is expressed in
the local body coordinate system.

As the ZMP is no longer useful in this case, we replace the ZMP
inequality constraints by the dynamic balance equality constraint from
Equation \equref{eq:chap3-dynamic-balance-inverse}. For now we assume
that the limiting coefficient of static friction $\mu_s$ is infinite,
i.e. that the friction cone is the positive half-space. We therefore
only add the first constraint from \equref{eq:chap3-friction-cone}, which
ensure that the contact force normals are positive.

We use the second phase of the martial arts scenario to verify our
approach with a set of coplanar contact points. As both feet of the
HRP-2 are on the horizontal floor, we first place one contact force on
each of the four foot vertices, which amounts to a total of 8
forces. We set the motion duration to $0.6$s in order to create a fast
trajectory.

Let the \emph{center of pressure (CoP)} be the contact point
barycenter, weighted by the normal contact forces. We plot the CoM,
ZMP and CoP in Figure
\ref{fig:chap3-contact-point6s-final-contact-edge}. Interestingly, the
ZMP and the CoP coincide over the shooting nodes, and differ only in
between, which confirms that the new dynamic balance formulation is
equivalent to the one using the ZMP when all contact points lie in the
same plane. We also notice that the ZMP is not always inside the support
polygon as the dynamic balance constraints are not enforced over the
sub-intervals. Figure
\ref{fig:chap3-contact-point6s-final-contact-reduced} shows the
resulting ZMP and CoP trajectories when placing contact forces on a
reduced support polygon vertices.

\begin{figure}
  \centering
  \begin{subfigure}{0.49\linewidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {contact-point6s-final-contact.pdf_tex}
          }
        }
        \caption{Contact forces applied at the foot edge vertices.}
        \label{fig:chap3-contact-point6s-final-contact-edge}
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {contact-point6s-final-point5contact-contact.pdf_tex}
          }
        }
        \caption{Contact forces applied on reduced support polygon.}
        \label{fig:chap3-contact-point6s-final-contact-reduced}
  \end{subfigure}
  \caption{Martial arts scenario, phase 2: trajectories of the ZMP and
    the CoP computed from the contact forces. Left: the dynamic
    balance constraints are enforced at the nodes, but the ZMP goes
    out the support polygon in two sub-intervals. Right: the ZMP stays
    inside the support polygon when more restrictive balance
    constraints, leading to a reduced support polygon, are used.}
  \label{fig:chap3-contact-point6s-final-contact}
\end{figure}

We show in Figure \ref{fig:chap3-contact-point6s-final-f} the normal
contact force values over time. Note that as the forces are required
to be non-vanishing, their normal components remain positive during
the whole motion. We also show the floating joint generalized force
constraint value in Figure
\ref{fig:chap3-contact-point6s-final-tau}; as expected, all
components are equal to zero at the shooting nodes, but the constraint
are not properly enforced in the sub-intervals. The values may seem
high, but they should be compared with other forces to which the robot
is subject, such as the gravity force. For instance the red and blue
line correspond to linear force components, and they represent less
than 5\% of the HRP2 weight, which is around 550N.

\begin{figure}
  \centering
  \begin{subfigure}{0.49\linewidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {contact-point6s-final-point5contact-lf.pdf_tex}
          }
        }
  \end{subfigure}
  \begin{subfigure}{0.49\linewidth}
    \centering
        {\def\svgwidth{\linewidth}
          {\tiny
            \subimport*{src/chap3-optimal-motion-planning/figure/}
                       {contact-point6s-final-point5contact-rf.pdf_tex}
          }
        }
  \end{subfigure}
  \caption{Martial arts scenario, phase 2: Left and right normal
    contact forces. All normal forces remain positive during the
    motion, and are computed to ensure dynamic balance.}
  \label{fig:chap3-contact-point6s-final-f}
\end{figure}

Finally, we confirm in Figure \ref{fig:chap3-contact-point6s-final-d}
that the collision avoidance constraints are properly enforced.

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {contact-point6s-final-point5contact-tau.pdf_tex}
        }
      }
  \caption{Martial arts scenario, phase 2: floating joint generalized
    torque evolution over time. It is required to be equal to 0 in
    order to obtain dynamic balance.}
  \label{fig:chap3-contact-point6s-final-tau}
\end{figure}

\begin{figure}
  \centering
      {\def\svgwidth{0.8\linewidth}
        {\scriptsize
          \subimport*{src/chap3-optimal-motion-planning/figure/}
                     {contact-point6s-final-d.pdf_tex}
        }
      }
  \caption{Martial arts scenario, phase 2: collision avoidance
    constraints evolution over time. The constraint violation does not
    exceed 2mm on the sub-intervals.}
  \label{fig:chap3-contact-point6s-final-d}
\end{figure}

In this work, we only tried enforcing dynamic balance constraints with
a contact force formulation in the case of horizontal coplanar contact
points. The same formulation can luckily be used for cases where the
contact points are not coplanar, e.g. where HRP-2 stands on an uneven
floor or uses its upper limbs to go in contact with the
environment. We leave this for future work.

\section{Discussions and Future Work}
\label{discussion}

In subsection \ref{test-case}, we demonstrate in a simple example the
influence of the initial guess of the optimal control problem on the
solver success and performance. In fact, due to its probabilistic
completeness, the usage of the constrained planner in a first stage
guarantees that an initial collision-free and quasi-statically
feasible trajectory can be found. The optimization solver then can
reshape this trajectory in order to minimize the objective function
while enforce constraints such as joint limits and dynamic
balance.

\paragraph{Solution optimality}
Note however that with this method, only locally optimal trajectories
are found; further investigation can be done in order to try to
transform the OCP into an equivalent convex optimization problem, as
this would allow both using simpler and more efficient solvers and
ensuring that global minimizers are computed. Such an approach has
been applied for time-optimal path tracking problem, see
\cite{verscheure2009time}. Alternatively, it might be interesting to
solve the optimal motion planning problem in one step using the
RRT$^*$ sampling-based planner, as described in Section
\ref{subsec:chap3-non-jacobian}.

\paragraph{Trajectory duration}
In this work, the trajectory duration is fixed in the OCP
formulation. This means that if it is not properly set, the
optimization solver might fail as some constraints such as velocity
limits would never be enforced. This issue could be solved by
including time as a variable in the OCP in order to guarantee the
complete framework succeeds in generating optimal
trajectories. However, this has to be done carefully: indeed, if time
is a free variable, the minimum-jerk trajectory will have an infinite
duration. One could choose to include time in the objective function,
so that both jerk and time are minimized, but a suitable weight ratio
for both terms then needs to be found, and the optimal trajectory
quality would be directly affected by those weights. An alternative
solution would be to add an additional stage in the framework: the
initial path would be first parameterized to an infinite-duration
trajectory, then a constrained minimum-time OCP would be solved, and
the solution would be finally used as an initial guess to solve the
constrained fixed-time minimum-jerk OCP we described in this work.

\paragraph{Computation time}
Obviously the optimal motion planning we described is still not meant
for online motion generation. In its current state, the two major
hurdles are the distance constraint computation and the optimal
control solver itself. We use the KCD library in order to successfully
compute distances between capsules and meshes; however, it not the
most efficient library and other ones such as the Flexible Collision
Library (FCL) \cite{pan2012fcl}, can be used for better
performance. Regarding the optimal control solver, \textsc{MUSCOD-II}
relies on an internal numerical differentiation mechanism to compute
all Jacobians. This is a very nice feature which allowed to formulate
an OCP very quickly without explicitly derivating the Jacobians, and
it leads to acceptable performance when the functions are not
expensive to compute. Sadly computing distances between capsules and
meshes is not very fast. Luckily their Jacobian is not very hard to
compute; it would be then useful to rely on solvers which can use the
Jacobian explicit expression.

One other possibility we did not explore is parallel computing;
indeed, dynamics, distance computation, and multiple shooting
algorithms all support parallelization; relying on smart GPU-based
implementations of these algorithms would obviously lead to enhanced
performance.

\paragraph{Enforcing constraints}
\textsc{MUSCOD-II} is based on a direct multiple shooting method. This
implies, as we saw in Section
\ref{subsubsec:chap3-direct-multiple-shooting}, that the OCP is
transcribed to a finite-dimensional NLP thanks to a discretization of
both the control and state vector. This also implies that constraints
are only enforced on the multiple shooting nodes, without any
guarantee that they will be valid over the time sub-intervals. As long
as we use enough nodes, this is not really an issue for constraints
that have slow dynamics such as kinematic constraints. This is not the
case for balance constraints such as the ZMP, and we needed to verify
a posteriori that they were enforced over the whole trajectory,
reducing the support polygon size when necessary.

In \cite{lengagne2013generation}, this issue is solved by locally
approximating constraints with Taylor polynomials, computing their
extremal values over each sub-interval of the time-grid, and using
them as effective constraints in the OCP formulation. Another possible
solution consist in relying on direct collocation methods; as the
control and state are finely discretized, constraints can be verified
almost everywhere on the trajectory.

\paragraph{Extension to non-coplanar contacts}
We showed in Section \ref{sec:chap3-noncoplanar-contact-points}
preliminary results of optimal control with a unilateral contact force
formulation which ensures balance. While we only applied it to
horizontal coplanar contact points, it can be used in the same way to
generate optimal motions with non-coplanar contact points. If we want
to handle correctly such cases in our optimal motion planning
framework, we equally need to plan statically balanced paths for
non-coplanar contact points. This implies redefining the planning
manifold $\manifold$ in order to enforce a generic stability criterion,
as described in \cite{bretl2006motion}, where a configuration and
contact forces are computed such that static balance is obtained.

\paragraph{Towards collision-free locomotion optimization}
In this work, we focused on generating motions under the assumption
that the set of contact points does not change during the whole
motion. It would be however interesting to consider optimal motion
planning for the more general case of locomotion, manipulation, or
both. As in \cite{lengagne2013generation}, our framework could be
extended, by planning and optimizing sequentially for multiple phases,
where each phase is defined by a fixed set of non-coplanar contact
points. This approach requires us to first plan the contact stance
sequence which cannot be changed later on.

An alternative solution would be to reformulate the OCP so that
changing contact point sets are taken into account, e.g. through a
linear complementarity constraint between a contact point distance to
obstacles and the normal contact force, as proposed in
\cite{posa2012direct, tassa2012synthesis,
  mordatch2012discovery}. Collision avoidance can be integrated in
this process by first planning a draft path, using high-level planners
such as the one we described in Chapter 2, and letting the optimizer
decide which contact points to use, and when to use them.

\section{Conclusion}
In this chapter we propose a novel approach to tackle optimal control
problems in cluttered environments. Our approach combines, in a
two-stage framework, a constrained path planning algorithm and an
optimal control problem solver. We generate optimal feasible
trajectories for the humanoid robot HRP-2 and successfully execute
them in constrained environments.

Our framework can benefit from improvements to increase its
usability. In future work we aim to consider non-coplanar contacts, as
well as release the robot from its fixed support constraints in order
to accomplish optimal locomotion planning.
